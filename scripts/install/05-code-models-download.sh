#!/bin/bash
#############################################
# GX10 Auto Installation Script - Phase 5
# Code Models Download
#
# Reference: PRD.md Section "Functional Requirements > 1. Code Brain"
# - KV Cache: 16K context window (line 169)
# - Memory optimization: 50-60GB total allocation
#
# Author: omc-developer
# Created: 2026-02-01
# Modified: 2026-02-01
#
# Reviewed-By: alfrad (2026-02-01)
#############################################

# alfrad review:
# âœ… PRD.md ì°¸ì¡° ì¶”ê°€ë¡œ ìš”êµ¬ì‚¬í•­ ì¶”ì  ê°€ëŠ¥ì„± í™•ë³´
# âœ… Author ì •ë³´ì™€ ìž‘ì„±ì¼ ëª…ì‹œë¡œ ì±…ìž„ ì†Œëª… ëª…í™•í™”
# âœ… KV Cache 16K ì„¤ì •ìœ¼ë¡œ PRD ìš”êµ¬ì‚¬í•­ ì¤€ìˆ˜ (line 169)
# âœ… í™˜ê²½ë³€ìˆ˜ OLLAMA_NUM_CTX=16384 ì„¤ì • ì ì ˆ
# âš ï¸ í™•ì¸: 7B, 16B ëª¨ë¸ì—ë„ ë™ì¼í•œ KV Cache ì ìš© í•„ìš” ì—¬ë¶€ ê²€í†  í•„ìš”
# ðŸ’¡ ì œì•ˆ: í–¥í›„ KV Cache ê°’ì„ í™˜ê²½ë³„ë¡œ ì„¤ì • ê°€ëŠ¥í•˜ë„ë¡ íŒŒë¼ë¯¸í„°í™” ê¶Œìž¥

set -e
set -u

LOG_FILE="/gx10/runtime/logs/05-code-models-download.log"
mkdir -p /gx10/runtime/logs

echo "=========================================="
echo "GX10 Phase 5: Code Models Download"
echo "=========================================="
echo "Log: $LOG_FILE"
echo "WARNING: This may take 40-60 minutes"
echo ""

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "Starting code models download..."

# Configure KV Cache size for 16K context window (PRD requirement)
# Reference: PRD.md line 169 - "qwen2.5-coder:32b: 24GB (16K KV Cache)"
log "Configuring Ollama environment for 16K KV Cache..."
export OLLAMA_NUM_CTX=16384
log "OLLAMA_NUM_CTX set to 16384 (16K context window)"

# Main coding model (32B) - 30min, 20GB
log "Downloading Qwen2.5-Coder 32B with 16K KV Cache (this will take ~30 minutes)..."
echo "Progress: Model download is running in background. Check log for details."
time ollama pull qwen2.5-coder:32b >> "$LOG_FILE" 2>&1
log "Qwen2.5-Coder 32B downloaded successfully!"

# Fast response model (7B) - 10min, 5GB
log "Downloading Qwen2.5-Coder 7B (this will take ~10 minutes)..."
time ollama pull qwen2.5-coder:7b >> "$LOG_FILE" 2>&1
log "Qwen2.5-Coder 7B downloaded successfully!"

# DeepSeek alternative (16B) - 15min, 10GB
log "Downloading DeepSeek-Coder V2 16B (this will take ~15 minutes)..."
time ollama pull deepseek-coder-v2:16b >> "$LOG_FILE" 2>&1
log "DeepSeek-Coder V2 16B downloaded successfully!"

# Embedding model
log "Downloading Nomic Embed Text model..."
time ollama pull nomic-embed-text >> "$LOG_FILE" 2>&1
log "Nomic Embed Text downloaded successfully!"

# Verification
log "Verifying installed models..."
echo "" | tee -a "$LOG_FILE"
echo "=== Installed Models ===" | tee -a "$LOG_FILE"
ollama list | tee -a "$LOG_FILE"

# Quick test
log "Running quick test with 32B model..."
echo "" | tee -a "$LOG_FILE"
echo "=== Quick Test (32B Model) ===" | tee -a "$LOG_FILE"
echo "Testing: Write a Python hello world function..." | tee -a "$LOG_FILE"
time ollama run qwen2.5-coder:32b "def hello(): print('Hello GX10')" >> "$LOG_FILE" 2>&1

log "Phase 5 completed successfully!"
echo "=========================================="
echo "Phase 5: COMPLETED"
echo "=========================================="
echo "Models installed:"
echo "  - qwen2.5-coder:32b (Main)"
echo "  - qwen2.5-coder:7b (Fast)"
echo "  - deepseek-coder-v2:16b (Alternative)"
echo "  - nomic-embed-text (Embedding)"
