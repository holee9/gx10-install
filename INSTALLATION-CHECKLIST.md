# GX10 êµ¬ì¶• ì ˆì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸

DGX OS 7.2.3ì´ ì„¤ì¹˜ëœ ASUS Ascent GX10ìš© êµ¬ì¶• ì ˆì°¨ì…ë‹ˆë‹¤.

## âœ… ì‚¬ì „ í™•ì¸ ì™„ë£Œ

- [x] DGX OS 7.2.3 ì„¤ì¹˜
- [x] SSH ì—°ê²° í™•ì¸

## ğŸ“‹ êµ¬ì¶• ì ˆì°¨

### Phase 1: ê¸°ë³¸ ì‹œìŠ¤í…œ ì„¤ì • (15ë¶„)

```bash
# 1. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
sudo apt update && sudo apt upgrade -y

# 2. í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜
sudo apt install -y build-essential git curl wget jq

# 3. Python ê°œë°œ ë„êµ¬ í™•ì¸ (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŒ)
python3 --version  # Python 3.12.x

# 4. DGX OS ì‚¬ì „ ì„¤ì¹˜ ì»´í¬ë„ŒíŠ¸ í™•ì¸
nvidia-smi          # NVIDIA ë“œë¼ì´ë²„
docker --version    # Docker
nvidia-ctk --version # NVIDIA Container Toolkit
```

### Phase 2: ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± (5ë¶„)

```bash
# 1. GX10 ê¸°ë³¸ ë””ë ‰í† ë¦¬
sudo mkdir -p /gx10/{api,brains/{code,vision},runtime/logs,system/monitoring}

# 2. Workspace ë””ë ‰í† ë¦¬
mkdir -p ~/workspace/{scripts,models,projects}

# 3. ì†Œìœ ê¶Œ ì„¤ì •
sudo chown -R $USER:$USER /gx10
```

### Phase 3: ìŠ¤í¬ë¦½íŠ¸ ì„¤ì¹˜ (10ë¶„)

```bash
# ê°œë°œì PCì—ì„œ GX10ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ ì „ì†¡
scp -r gx10-scripts/ user@gx10-brain.local:/tmp/

# GX10 ì„œë²„ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì„¤ì¹˜
cd /tmp/gx10-scripts

# API ìŠ¤í¬ë¦½íŠ¸
cp api/*.sh /gx10/api/
chmod +x /gx10/api/*.sh

# Vision Brain
cp brains/vision/*.{sh,Dockerfile} /gx10/brains/vision/
chmod +x /gx10/brains/vision/run.sh

# ì‹œìŠ¤í…œ ìŠ¤í¬ë¦½íŠ¸
cp system/start-all.sh /gx10/system/
cp system/monitoring/health-check.sh /gx10/system/monitoring/
chmod +x /gx10/system/start-all.sh
chmod +x /gx10/system/monitoring/health-check.sh

# Workspace ìŠ¤í¬ë¦½íŠ¸
cp workspace-scripts/*.sh ~/workspace/scripts/
chmod +x ~/workspace/scripts/*.sh
```

### Phase 4: Ollama ì„¤ì¹˜ (10ë¶„)

```bash
# 1. Ollama ì„¤ì¹˜
curl -fsSL https://ollama.com/install.sh | sh

# 2. systemd ì„œë¹„ìŠ¤ ì„¤ì •
sudo mkdir -p /etc/systemd/system/ollama.service.d
sudo tee /etc/systemd/system/ollama.service.d/override.conf << EOF
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_MODELS=/gx10/brains/code/models"
Environment="OLLAMA_KEEP_ALIVE=24h"
Environment="OLLAMA_NUM_PARALLEL=2"
Environment="OLLAMA_MAX_LOADED_MODELS=2"
EOF

# 3. ì„œë¹„ìŠ¤ í™œì„±í™”
sudo systemctl daemon-reload
sudo systemctl enable ollama
sudo systemctl start ollama

# 4. ì„¤ì¹˜ í™•ì¸
ollama --version
curl http://localhost:11434/api/version
```

### Phase 5: Code Brain ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (60ë¶„)

```bash
# ë©”ì¸ ì½”ë”© ëª¨ë¸ (32B) - ì•½ 30ë¶„
ollama pull qwen2.5-coder:32b

# ë¹ ë¥¸ ì‘ë‹µìš© (7B) - ì•½ 10ë¶„
ollama pull qwen2.5-coder:7b

# ëŒ€ì•ˆ: DeepSeek (16B) - ì•½ 15ë¶„
ollama pull deepseek-coder-v2:16b

# ì„ë² ë”© ëª¨ë¸
ollama pull nomic-embed-text

# ì„¤ì¹˜ í™•ì¸
ollama list
```

### Phase 6: Vision Brain ë¹Œë“œ (30ë¶„)

```bash
# 1. Dockerfile í™•ì¸
cat /gx10/brains/vision/Dockerfile

# 2. ì´ë¯¸ì§€ ë¹Œë“œ (ì•½ 20-30ë¶„)
cd /gx10/brains/vision
docker build -t gx10-vision-brain:latest .

# 3. ë¹Œë“œ í™•ì¸
docker images | grep gx10-vision-brain
```

### Phase 7: bashrc ì„¤ì • (5ë¶„)

```bash
cat >> ~/.bashrc << 'EOF'

# GX10 AI System Aliases (DGX OS)
alias gx-status='/gx10/api/status.sh'
alias gx-switch='/gx10/api/switch.sh'
alias gx-start='/gx10/system/start-all.sh'
alias ai-start='~/workspace/scripts/start-all.sh'
alias ai-status='~/workspace/scripts/status.sh'

# Quick model access
alias chat='ollama run qwen2.5-coder:32b'
alias chat-fast='ollama run qwen2.5-coder:7b'
alias vision='ollama run qwen2.5-vl:7b'

# DGX Dashboard
alias dgx-dash='echo "Access DGX Dashboard at: https://$(hostname -I | awk '"'"'{print $1}'"'"'):6789"'
EOF

source ~/.bashrc
```

### Phase 8: Health Check cron ì„¤ì • (2ë¶„)

```bash
# 5ë¶„ë§ˆë‹¤ í—¬ìŠ¤ì²´í¬
(crontab -l 2>/dev/null; echo "*/5 * * * * /gx10/system/monitoring/health-check.sh") | crontab -

# ë¶€íŒ… ì‹œ ìë™ ì‹œì‘
(crontab -l 2>/dev/null; echo "@reboot sleep 60 && /gx10/system/start-all.sh >> /gx10/runtime/logs/startup.log 2>&1") | crontab -
```

### Phase 9: ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (10ë¶„)

```bash
# 1. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
gx-status

# 2. Ollama í…ŒìŠ¤íŠ¸
ollama run qwen2.5-coder:32b "Write a Python hello world"

# 3. Brain ì „í™˜ í…ŒìŠ¤íŠ¸
gx-switch code
sleep 5
gx-switch vision
sleep 5
gx-switch code

# 4. í—¬ìŠ¤ì²´í¬ í™•ì¸
/gx10/system/monitoring/health-check.sh
cat /gx10/runtime/logs/health.log
```

## ğŸ¯ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•„ìˆ˜ í•­ëª©

- [ ] ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ
- [ ] ìŠ¤í¬ë¦½íŠ¸ ì„¤ì¹˜ ì™„ë£Œ
- [ ] Ollama ì„¤ì¹˜ ë° ì„œë¹„ìŠ¤ ë“±ë¡ ì™„ë£Œ
- [ ] ë©”ì¸ ì½”ë”© ëª¨ë¸ (32B) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [ ] bashrc alias ì„¤ì • ì™„ë£Œ
- [ ] í—¬ìŠ¤ì²´í¬ cron ë“±ë¡ ì™„ë£Œ
- [ ] ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í†µê³¼

### ì„ íƒ í•­ëª©

- [ ] ë¹ ë¥¸ ëª¨ë¸ (7B) ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [ ] DeepSeek ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [ ] Vision Brain Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ
- [ ] Open WebUI ì„¤ì¹˜ (ì¶”í›„)
- [ ] n8n ì„¤ì¹˜ (ì¶”í›„)

## ğŸ“Š ì´ ì†Œìš” ì‹œê°„

| í•­ëª© | ì‹œê°„ |
|------|------|
| Phase 1-3 (ê¸°ë³¸ ì„¤ì •) | 30ë¶„ |
| Phase 4 (Ollama) | 10ë¶„ |
| Phase 5 (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ) | 60ë¶„ |
| Phase 6 (Vision Brain) | 30ë¶„ |
| Phase 7-9 (ì„¤ì •) | 20ë¶„ |
| **ì´í•©** | **ì•½ 2.5ì‹œê°„** |

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (ìµœì†Œ)

```bash
# 1ì¤„ ì„¤ì¹˜
curl -fsSL https://ollama.com/install.sh | sh && \
sudo systemctl enable ollama && sudo systemctl start ollama && \
ollama pull qwen2.5-coder:32b && \
ollama run qwen2.5-coder:32b "Hello, GX10!"
```

## ğŸ“ ë¬¸ì œ í•´ê²°

### ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ

```bash
# DGX OSì— ì‚¬ì „ ì„¤ì¹˜ëœ ì»´í¬ë„ŒíŠ¸ í™•ì¸
which nvidia-smi
which docker
which nvidia-ctk

# ê²½ë¡œ í™•ì¸
echo $PATH | tr ':' '\n'
```

### ê¶Œí•œ ë¬¸ì œ

```bash
# sudo ê·¸ë£¹ í™•ì¸
groups

# docker ê·¸ë£¹ì— ì¶”ê°€ (í•„ìš”ì‹œ)
sudo usermod -aG docker $USER
newgrp docker
```

### Ollama ì—°ê²° ì‹¤íŒ¨

```bash
# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo systemctl status ollama

# ë¡œê·¸ í™•ì¸
journalctl -u ollama -f

# ì¬ì‹œì‘
sudo systemctl restart ollama
```

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

ëª¨ë“  ì„¤ì • ì™„ë£Œ í›„:
1. ê°œë°œì PCì—ì„œ SSH í„°ë„ ìƒì„±
2. Aider/Continue.dev ì—°ê²° ì„¤ì •
3. ì²« ë²ˆì§¸ í”„ë¡œì íŠ¸ ì‹œì‘

---

*ì´ ì²´í¬ë¦¬ìŠ¤íŠ¸ëŠ” DGX OS 7.2.3 í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.*
