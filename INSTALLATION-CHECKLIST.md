# GX10 êµ¬ì¶• ì ˆì°¨ ì²´í¬ë¦¬ìŠ¤íŠ¸

DGX OS 7.2.3ì´ ì„¤ì¹˜ëœ ASUS Ascent GX10ìš© êµ¬ì¶• ì ˆì°¨ì…ë‹ˆë‹¤.

## âœ… ì‚¬ì „ ì ê²€ ê²°ê³¼ (2026-02-03 ì‹¤ì¸¡)

### ì‹œìŠ¤í…œ ìƒíƒœ

| í•­ëª© | ìƒíƒœ | ìƒì„¸ |
|------|------|------|
| OS | âœ… ì •ìƒ | Ubuntu 24.04.3 LTS (DGX OS), aarch64, Kernel 6.14.0-1015-nvidia |
| GPU | âœ… ì •ìƒ | NVIDIA GB10, 37Â°C, CUDA 13.0, Driver 580.126.09 |
| ë©”ëª¨ë¦¬ | âœ… ì •ìƒ | ì´ 119GB / ì‚¬ìš© 4.1GB / ê°€ìš© 115GB, ìŠ¤ì™‘ 15GB |
| ë””ìŠ¤í¬ | âœ… ì •ìƒ | 916GB ì¤‘ 38GB ì‚¬ìš© (832GB ê°€ìš©) |
| ì¸í„°ë„· | âœ… ì •ìƒ | ì™¸ë¶€ ì—°ê²° í™•ì¸ë¨ |
| ê¸°ë³¸ ë„êµ¬ | âœ… ì •ìƒ | git, curl, wget, python3 ì„¤ì¹˜ë¨ |
| NVIDIA Container Toolkit | âœ… ì •ìƒ | v1.18.2 |
| Docker Engine | âœ… ì„¤ì¹˜ë¨ | v28.5.1 (Docker Compose v2.40.0, Buildx v0.29.1) |
| /gx10 ë””ë ‰í† ë¦¬ | âš ï¸ êµ¬ì¡°ë§Œ ì¡´ì¬ | api, brains, system, automation, runtime (ë‚´ìš© ë¹„ì–´ìˆìŒ) |
| Docker ê·¸ë£¹ ê¶Œí•œ | âš ï¸ ìˆ˜ë™ ì„¤ì • í•„ìš” | `sudo usermod -aG docker holee` ì‹¤í–‰ í•„ìš” |
| Ollama | âŒ ë¯¸ì„¤ì¹˜ | `curl -fsSL https://ollama.com/install.sh \| sudo sh` í•„ìš” |
| AI ëª¨ë¸ | âŒ ì—†ìŒ | Ollama ì„¤ì¹˜ í›„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš” |

### ì‚¬ì „ í™•ì¸ ì™„ë£Œ

- [x] DGX OS 7.2.3 ì„¤ì¹˜
- [x] SSH ì—°ê²° í™•ì¸
- [x] GPU ë“œë¼ì´ë²„ ì •ìƒ (CUDA 13.0)
- [x] Docker Engine ì„¤ì¹˜ë¨ (v28.5.1)
- [x] NVIDIA Container Toolkit ì„¤ì¹˜ë¨ (v1.18.2)
- [x] ê¸°ë³¸ ê°œë°œ ë„êµ¬ ì„¤ì¹˜ë¨ (git, curl, wget, python3)
- [x] /gx10 ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±ë¨
- [x] ë””ìŠ¤í¬ ê³µê°„ ì¶©ë¶„ (832GB ê°€ìš©)
- [x] ë©”ëª¨ë¦¬ ì¶©ë¶„ (115GB ê°€ìš©)
- [x] Docker ê·¸ë£¹ ê¶Œí•œ ì„¤ì • (Phase 0ì—ì„œ ì™„ë£Œ)
- [x] Ollama ì„¤ì¹˜ (Phase 0ì—ì„œ ì™„ë£Œ, v0.15.4)
- [x] Ollama models ë””ë ‰í† ë¦¬ ê¶Œí•œ ìˆ˜ì • (`chown ollama:ollama` â€” KB-002 ì°¸ì¡°)
- [ ] AI ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

## ğŸ“‹ êµ¬ì¶• ì ˆì°¨

### Phase 0: Sudo ì‚¬ì „ ì‹¤í–‰ (15-20ë¶„) â­ ê¶Œì¥

**ëª¨ë“  sudo í•„ìš” ì‘ì—…ì„ í•œ ë²ˆì— ì‹¤í–‰í•©ë‹ˆë‹¤.** ì´í›„ ë‹¨ê³„ëŠ” sudo ì—†ì´ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.

```bash
cd scripts/install
sudo ./00-sudo-prereqs.sh
```

Phase 0ì´ ìˆ˜í–‰í•˜ëŠ” ì‘ì—… (8ê°œ ì„¹ì…˜):
1. ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜ (apt update/upgrade, ê°œë°œ ë„êµ¬)
2. SSH í™œì„±í™” ë° ë°©í™”ë²½ ì„¤ì • (í¬íŠ¸ 22, 11434, 8080, 5678)
3. /gx10 ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± + ì†Œìœ ê¶Œ (âš ï¸ models â†’ `ollama:ollama`, KB-002)
4. Docker ê·¸ë£¹ì— ì‚¬ìš©ì ì¶”ê°€
5. Ollama ì„¤ì¹˜
6. Ollama systemd ì„œë¹„ìŠ¤ ì„¤ì • (override.conf)
7. ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ë“±ë¡
8. Brain ì „í™˜ sudoers ì„¤ì • + /usr/local/bin wrapper (KB-004)

**Phase 0 ì™„ë£Œ í›„ ë°˜ë“œì‹œ ì¬ë¡œê·¸ì¸** (docker ê·¸ë£¹ ë°˜ì˜):
```bash
# ë°©ë²• 1: ì¬ë¡œê·¸ì¸
logout
# ë‹¤ì‹œ ë¡œê·¸ì¸

# ë°©ë²• 2: newgrp (í˜„ì¬ ì„¸ì…˜ì—ì„œ)
newgrp docker
```

### [ë ˆê±°ì‹œ] ê¸°ë³¸ ì‹œìŠ¤í…œ ì„¤ì • (Phase 0ì— í†µí•©ë¨)

> Phase 0ì„ ì‹¤í–‰í–ˆë‹¤ë©´ ì´ ë‹¨ê³„ëŠ” ê±´ë„ˆë›°ì„¸ìš”.

```bash
# 1. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
sudo apt update && sudo apt upgrade -y

# 2. í•„ìˆ˜ ë„êµ¬ ì„¤ì¹˜
sudo apt install -y build-essential git curl wget jq

# 3. Python ê°œë°œ ë„êµ¬ í™•ì¸ (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŒ)
python3 --version  # Python 3.12.x

# 4. DGX OS ì‚¬ì „ ì„¤ì¹˜ ì»´í¬ë„ŒíŠ¸ í™•ì¸
nvidia-smi          # NVIDIA ë“œë¼ì´ë²„
docker --version    # Docker
nvidia-ctk --version # NVIDIA Container Toolkit
```

### [ë ˆê±°ì‹œ] ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± (Phase 0ì— í†µí•©ë¨)

> Phase 0ì„ ì‹¤í–‰í–ˆë‹¤ë©´ ì´ ë‹¨ê³„ëŠ” ê±´ë„ˆë›°ì„¸ìš”.

```bash
# 1. GX10 ê¸°ë³¸ ë””ë ‰í† ë¦¬
sudo mkdir -p /gx10/{api,brains/{code,vision},runtime/logs,system/monitoring}

# 2. Workspace ë””ë ‰í† ë¦¬
mkdir -p ~/workspace/{scripts,models,projects}

# 3. ì†Œìœ ê¶Œ ì„¤ì •
sudo chown -R $USER:$USER /gx10
```

### [ë ˆê±°ì‹œ] ìŠ¤í¬ë¦½íŠ¸ ì„¤ì¹˜ (Phase 0ì— í†µí•©ë¨)

```bash
# ê°œë°œì PCì—ì„œ GX10ìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸ ì „ì†¡
scp -r gx10-scripts/ user@gx10-brain.local:/tmp/

# GX10 ì„œë²„ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì„¤ì¹˜
cd /tmp/gx10-scripts

# API ìŠ¤í¬ë¦½íŠ¸
cp api/*.sh /gx10/api/
chmod +x /gx10/api/*.sh

# Vision Brain
cp brains/vision/*.{sh,Dockerfile} /gx10/brains/vision/
chmod +x /gx10/brains/vision/run.sh

# ì‹œìŠ¤í…œ ìŠ¤í¬ë¦½íŠ¸
cp system/start-all.sh /gx10/system/
cp system/monitoring/health-check.sh /gx10/system/monitoring/
chmod +x /gx10/system/start-all.sh
chmod +x /gx10/system/monitoring/health-check.sh

# Workspace ìŠ¤í¬ë¦½íŠ¸
cp workspace-scripts/*.sh ~/workspace/scripts/
chmod +x ~/workspace/scripts/*.sh
```

### [ë ˆê±°ì‹œ] Ollama ì„¤ì¹˜ (Phase 0ì— í†µí•©ë¨)

> Phase 0ì„ ì‹¤í–‰í–ˆë‹¤ë©´ ì´ ë‹¨ê³„ëŠ” ê±´ë„ˆë›°ì„¸ìš”.

```bash
# 1. Ollama ì„¤ì¹˜
curl -fsSL https://ollama.com/install.sh | sh

# 2. systemd ì„œë¹„ìŠ¤ ì„¤ì •
sudo mkdir -p /etc/systemd/system/ollama.service.d
sudo tee /etc/systemd/system/ollama.service.d/override.conf << EOF
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_MODELS=/gx10/brains/code/models"
Environment="OLLAMA_KEEP_ALIVE=24h"
Environment="OLLAMA_NUM_PARALLEL=2"
Environment="OLLAMA_MAX_LOADED_MODELS=2"
EOF

# 3. ì„œë¹„ìŠ¤ í™œì„±í™”
sudo systemctl daemon-reload
sudo systemctl enable ollama
sudo systemctl start ollama

# 4. ì„¤ì¹˜ í™•ì¸
ollama --version
curl http://localhost:11434/api/version
```

### Phase 1: Code Brain ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (40-60ë¶„, sudo ë¶ˆí•„ìš”)

```bash
# ë©”ì¸ ì½”ë”© ëª¨ë¸ (32B) - ì•½ 30ë¶„
ollama pull qwen2.5-coder:32b

# ë¹ ë¥¸ ì‘ë‹µìš© (7B) - ì•½ 10ë¶„
ollama pull qwen2.5-coder:7b

# ëŒ€ì•ˆ: DeepSeek (16B) - ì•½ 15ë¶„
ollama pull deepseek-coder-v2:16b

# ì„ë² ë”© ëª¨ë¸
ollama pull nomic-embed-text

# ì„¤ì¹˜ í™•ì¸
ollama list
```

### Phase 2: Vision Brain ë¹Œë“œ (20-30ë¶„, sudo ë¶ˆí•„ìš”)

```bash
# 1. Dockerfile í™•ì¸
cat /gx10/brains/vision/Dockerfile

# 2. ì´ë¯¸ì§€ ë¹Œë“œ (ì•½ 20-30ë¶„)
cd /gx10/brains/vision
docker build -t gx10-vision-brain:latest .

# 3. ë¹Œë“œ í™•ì¸
docker images | grep gx10-vision-brain
```

### Phase 3: bashrc ì„¤ì • (5ë¶„, sudo ë¶ˆí•„ìš”)

```bash
cat >> ~/.bashrc << 'EOF'

# GX10 AI System Aliases (DGX OS)
alias gx-status='/gx10/api/status.sh'
alias gx-switch='/gx10/api/switch.sh'
alias gx-start='/gx10/system/start-all.sh'
alias ai-start='~/workspace/scripts/start-all.sh'
alias ai-status='~/workspace/scripts/status.sh'

# Quick model access
alias chat='ollama run qwen2.5-coder:32b'
alias chat-fast='ollama run qwen2.5-coder:7b'
alias vision='ollama run qwen2.5-vl:7b'

# DGX Dashboard
alias dgx-dash='echo "Access DGX Dashboard at: https://$(hostname -I | awk '"'"'{print $1}'"'"'):6789"'
EOF

source ~/.bashrc
```

### Phase 4: Health Check cron ì„¤ì • (2ë¶„, sudo ë¶ˆí•„ìš”)

```bash
# 5ë¶„ë§ˆë‹¤ í—¬ìŠ¤ì²´í¬
(crontab -l 2>/dev/null; echo "*/5 * * * * /gx10/system/monitoring/health-check.sh") | crontab -

# ë¶€íŒ… ì‹œ ìë™ ì‹œì‘
(crontab -l 2>/dev/null; echo "@reboot sleep 60 && /gx10/system/start-all.sh >> /gx10/runtime/logs/startup.log 2>&1") | crontab -
```

### Phase 5: ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (10ë¶„, sudo ë¶ˆí•„ìš”)

```bash
# 1. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
gx-status

# 2. Ollama í…ŒìŠ¤íŠ¸
ollama run qwen2.5-coder:32b "Write a Python hello world"

# 3. Brain ì „í™˜ í…ŒìŠ¤íŠ¸
gx-switch code
sleep 5
gx-switch vision
sleep 5
gx-switch code

# 4. í—¬ìŠ¤ì²´í¬ í™•ì¸
/gx10/system/monitoring/health-check.sh
cat /gx10/runtime/logs/health.log
```

## ğŸ¯ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 0: Sudo ì‚¬ì „ ì‹¤í–‰ (2026-02-03 10:15 ì™„ë£Œ)

- [x] ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ (31ê°œ ì—…ê·¸ë ˆì´ë“œ, 27ê°œ ì‹ ê·œ)
- [x] SSH í™œì„±í™” ë° ë°©í™”ë²½ ì„¤ì • (í¬íŠ¸ 22, 11434, 8080, 5678)
- [x] /gx10 ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± (23ê°œ ë””ë ‰í† ë¦¬, holee ì†Œìœ )
- [x] Docker ê·¸ë£¹ ë“±ë¡ (holee â†’ docker ê·¸ë£¹)
- [x] Ollama ì„¤ì¹˜ (v0.15.4)
- [x] Ollama systemd override ì„¤ì • (OLLAMA_HOST=0.0.0.0, MODELS=/gx10/brains/code/models)
- [x] ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ë“±ë¡ (gx10-monitor.service/timer)

### Phase 0 í›„ì† ì¡°ì¹˜ (ìˆ˜ë™ í•„ìš”)

- [ ] Ollama ì„œë¹„ìŠ¤ ì •ìƒ ê¸°ë™ í™•ì¸ (`sudo systemctl restart ollama` â†’ `ollama list`)
- [ ] Docker ì„¸ì…˜ ë°˜ì˜ (Claude Code ì¬ì‹œì‘ ë˜ëŠ” `newgrp docker` â†’ `docker ps`)

### Phase 1: Code Brain ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

- [ ] ë©”ì¸ ì½”ë”© ëª¨ë¸ (qwen2.5-coder:32b) ë‹¤ìš´ë¡œë“œ
- [ ] ë¹ ë¥¸ ëª¨ë¸ (qwen2.5-coder:7b) ë‹¤ìš´ë¡œë“œ

### Phase 2: Vision Brain ì„¤ì¹˜

- [ ] Vision Brain Docker ì´ë¯¸ì§€ ë¹Œë“œ
- [ ] Brain ì „í™˜ API ë°°í¬

### Phase 3-4: ì„œë¹„ìŠ¤ ë° ì„¤ì •

- [ ] bashrc alias ì„¤ì •
- [ ] Open WebUI ì„¤ì¹˜
- [ ] í—¬ìŠ¤ì²´í¬ cron ë“±ë¡

### Phase 5: ê²€ì¦

- [ ] ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] Brain ì „í™˜ í…ŒìŠ¤íŠ¸ (Code â†” Vision)
- [ ] ê°œë°œì PC ì—°ë™ í™•ì¸

### ì„ íƒ í•­ëª©

- [ ] DeepSeek ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [ ] ì„ë² ë”© ëª¨ë¸ (nomic-embed-text) ë‹¤ìš´ë¡œë“œ
- [ ] n8n ì›Œí¬í”Œë¡œìš° ì„¤ì¹˜
- [ ] MCP ì„œë²„ ì„¤ì¹˜

## ğŸ“Š ì´ ì†Œìš” ì‹œê°„ (2026-02-03 Phase 0 ì™„ë£Œ í›„ ìˆ˜ì •)

| í•­ëª© | ì „ì²´ ì‹œê°„ | ë‚¨ì€ ì‹œê°„ | ë¹„ê³  |
|------|---------|---------|------|
| ~~Phase 0 (sudo ì‚¬ì „ì‹¤í–‰)~~ | ~~15-20ë¶„~~ | ~~ì™„ë£Œ~~ | âœ… 2ë¶„ ì†Œìš” (ëŒ€ë¶€ë¶„ ì´ë¯¸ ì„¤ì¹˜ë¨) |
| Phase 0 í›„ì† (ìˆ˜ë™) | 2ë¶„ | 2ë¶„ | Ollama ì¬ì‹œì‘ + Docker ì„¸ì…˜ ë°˜ì˜ |
| Phase 1 (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ) | 50ë¶„ | 50ë¶„ | qwen2.5-coder:32b + 7b |
| Phase 2 (Vision Brain) | 25ë¶„ | 25ë¶„ | Docker ë¹Œë“œ(20ë¶„) + API(5ë¶„) |
| Phase 3-4 (ì„œë¹„ìŠ¤/ì„¤ì •) | 10ë¶„ | 10ë¶„ | bashrc, WebUI, cron |
| Phase 5 (ê²€ì¦) | 10ë¶„ | 10ë¶„ | ì „ì²´ í…ŒìŠ¤íŠ¸ + Brain ì „í™˜ |
| **ì´í•©** | | **~1ì‹œê°„ 37ë¶„** | Phase 0 ì™„ë£Œ, í›„ì† ì¡°ì¹˜ 2ê±´ í•„ìš” |

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ê¶Œì¥: Phase 0 â†’ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (2-Step)

```bash
# Step 1: sudo ì‚¬ì „ ì‹¤í–‰ (15-20ë¶„, í•œ ë²ˆë§Œ)
cd ~/workspace/gx10-install/scripts/install
sudo ./00-sudo-prereqs.sh

# Step 2: ì¬ë¡œê·¸ì¸ í›„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (sudo ë¶ˆí•„ìš”)
ollama pull qwen2.5-coder:32b && \
ollama run qwen2.5-coder:32b "Hello, GX10!"
```

### ìµœì†Œ ì„¤ì¹˜ (1-liner, sudo í™˜ê²½)

```bash
curl -fsSL https://ollama.com/install.sh | sudo sh && \
sudo systemctl enable ollama && sudo systemctl start ollama && \
ollama pull qwen2.5-coder:32b && \
ollama run qwen2.5-coder:32b "Hello, GX10!"
```

## ğŸ“ ë¬¸ì œ í•´ê²°

### ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ

```bash
# DGX OSì— ì‚¬ì „ ì„¤ì¹˜ëœ ì»´í¬ë„ŒíŠ¸ í™•ì¸
which nvidia-smi
which docker
which nvidia-ctk

# ê²½ë¡œ í™•ì¸
echo $PATH | tr ':' '\n'
```

### ê¶Œí•œ ë¬¸ì œ

```bash
# sudo ê·¸ë£¹ í™•ì¸
groups

# docker ê·¸ë£¹ì— ì¶”ê°€ (í•„ìš”ì‹œ)
sudo usermod -aG docker $USER
newgrp docker
```

### Ollama ì—°ê²° ì‹¤íŒ¨

```bash
# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo systemctl status ollama

# ë¡œê·¸ í™•ì¸
journalctl -u ollama -f

# ì¬ì‹œì‘
sudo systemctl restart ollama
```

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

ëª¨ë“  ì„¤ì • ì™„ë£Œ í›„:
1. ê°œë°œì PCì—ì„œ SSH í„°ë„ ìƒì„±
2. Aider/Continue.dev ì—°ê²° ì„¤ì •
3. ì²« ë²ˆì§¸ í”„ë¡œì íŠ¸ ì‹œì‘

---

*ì´ ì²´í¬ë¦¬ìŠ¤íŠ¸ëŠ” DGX OS 7.2.3 í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.*

---

## ğŸ“œ ì„¤ì¹˜ ì§„í–‰ ë¡œê·¸

### 2026-02-03: ì‚¬ì „ ì ê²€ ì‹¤ì‹œ

**ì‹¤í–‰ í™˜ê²½**: GX10 ë³¸ì²´ ì§ì ‘ ì ‘ì† (Claude Code)

**ì ê²€ ê²°ê³¼ ìš”ì•½**:
- OS/ì»¤ë„/GPU/ë©”ëª¨ë¦¬/ë””ìŠ¤í¬: ëª¨ë‘ ì •ìƒ
- Docker Engine v28.5.1 ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë‚˜, ì‚¬ìš©ì `holee`ê°€ `docker` ê·¸ë£¹ì— ë¯¸ë“±ë¡
- NVIDIA Container Toolkit v1.18.2 ì •ìƒ ì„¤ì¹˜
- `/gx10/` ë””ë ‰í† ë¦¬ ê¸°ë³¸ êµ¬ì¡°(api, brains, system, automation, runtime) ì¡´ì¬í•˜ë‚˜ ë‚´ìš© ë¹„ì–´ìˆìŒ
- Ollama ë¯¸ì„¤ì¹˜ ìƒíƒœ
- AI ëª¨ë¸ ì—†ìŒ

**í•„ìš” ì¡°ì¹˜**:
1. `sudo ./scripts/install/00-sudo-prereqs.sh` ì‹¤í–‰ â†’ ëª¨ë“  sudo ì‘ì—… ì¼ê´„ ì²˜ë¦¬
2. ì¬ë¡œê·¸ì¸ (docker ê·¸ë£¹ ë°˜ì˜)
3. ì´í›„ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì„œë¹„ìŠ¤ ì„¤ì •ì€ Claude Codeì—ì„œ ìë™í™” ê°€ëŠ¥

**ì§„í–‰ë„**: ì•½ 30% (ê¸°ë³¸ ì¸í”„ë¼ í™•ì¸ ì™„ë£Œ)

**ëŒ€ì‘**: `00-sudo-prereqs.sh` ìŠ¤í¬ë¦½íŠ¸ ìƒì„±í•˜ì—¬ ëª¨ë“  sudo ì‘ì—…ì„ ì‚¬ì „ì— ì¼ê´„ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±

### 2026-02-03 10:15: Phase 0 ì‹¤í–‰ ì™„ë£Œ

**ì‹¤í–‰ ê²°ê³¼**: `sudo ./00-sudo-prereqs.sh` - ì „ì²´ ì„±ê³µ (ì•½ 2ë¶„ ì†Œìš”)

| ì„¹ì…˜ | ê²°ê³¼ | ë¹„ê³  |
|------|------|------|
| Section 1: íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ | âœ… ì„±ê³µ | 31ê°œ ì—…ê·¸ë ˆì´ë“œ + 27ê°œ ì‹ ê·œ ì„¤ì¹˜ (Docker CE 29.1.3, neovim ë“±) |
| Section 2: SSH/ë°©í™”ë²½ | âœ… ì„±ê³µ | UFW í™œì„±í™”, í¬íŠ¸ 22/11434/8080/5678 í—ˆìš© |
| Section 3: ë””ë ‰í† ë¦¬ êµ¬ì¡° | âœ… ì„±ê³µ | /gx10 ì „ì²´ 23ê°œ ë””ë ‰í† ë¦¬ ìƒì„±, holee ì†Œìœ ê¶Œ |
| Section 4: Docker ê·¸ë£¹ | âœ… ì´ë¯¸ ë“±ë¡ë¨ | holee ì‚¬ìš©ì docker ê·¸ë£¹ í™•ì¸ë¨ |
| Section 5: Ollama ì„¤ì¹˜ | âœ… ì´ë¯¸ ì„¤ì¹˜ë¨ | v0.15.4 |
| Section 6: Ollama ì„œë¹„ìŠ¤ | âœ… ì„±ê³µ | override.conf ìƒì„±, ì„œë¹„ìŠ¤ ì¬ì‹œì‘ |
| Section 7: ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ | âœ… ì„±ê³µ | gx10-monitor.service/timer ë“±ë¡ |

**ë°œê²¬ëœ ë¬¸ì œ (2ê±´)**:

1. **Ollama ì„œë¹„ìŠ¤ ë¯¸ì‘ë‹µ**: `ollama list` ì‹¤í–‰ ì‹œ "ollama server not responding" ì˜¤ë¥˜
   - override.conf ì ìš©ì€ ë˜ì—ˆìœ¼ë‚˜ ì„œë¹„ìŠ¤ê°€ ì •ìƒ ê¸°ë™ë˜ì§€ ì•ŠìŒ
   - ì›ì¸: `/gx10/brains/code/models` ë””ë ‰í† ë¦¬ë¥¼ OLLAMA_MODELSë¡œ ì„¤ì •í–ˆìœ¼ë‚˜ ëª¨ë¸ íŒŒì¼ ì—†ìŒ
   - ì¡°ì¹˜: `sudo systemctl restart ollama` ë˜ëŠ” `ollama serve` ìˆ˜ë™ ì‹œì‘ í•„ìš”

2. **Docker ì†Œì¼“ ê¶Œí•œ**: `docker ps` ì‹¤í–‰ ì‹œ permission denied
   - docker ê·¸ë£¹ì— ë“±ë¡ë˜ì—ˆìœ¼ë‚˜(uid 988) **í˜„ì¬ ì„¸ì…˜ì— ë¯¸ë°˜ì˜**
   - ì¡°ì¹˜: Claude Code ì¬ì‹œì‘ ë˜ëŠ” `newgrp docker` í•„ìš”
